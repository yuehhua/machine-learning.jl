{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = DecisionTree.load_data(\"iris\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Array{String,1}:\n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " \"Iris-setosa\"   \n",
       " ⋮               \n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = float.(features)\n",
    "labels = string.(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier\n",
       "n_trees:             50\n",
       "n_subfeatures:       -1\n",
       "partial_sampling:    0.7\n",
       "max_depth:           2\n",
       "min_samples_leaf:    1\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "classes:             ensemble:            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing\n",
      "nothing"
     ]
    }
   ],
   "source": [
    "model = DecisionTree.RandomForestClassifier(n_trees=50, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available models:\n",
    "\n",
    "* `DecisionTreeClassifier`\n",
    "* `DecisionTreeRegressor`\n",
    "* `RandomForestClassifier`\n",
    "* `RandomForestRegressor`\n",
    "* `AdaBoostStumpClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "RandomForestClassifier(; n_subfeatures::Int=-1,\n",
       "                       n_trees::Int=10,\n",
       "                       partial_sampling::Float=0.7,\n",
       "                       max_depth::Int=-1,\n",
       "                       rng=Random.GLOBAL_RNG)\n",
       "\\end{verbatim}\n",
       "Random forest classification. See \\href{https://github.com/bensadeghi/DecisionTree.jl}{DecisionTree.jl's documentation}\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{n\\_subfeatures}: number of features to consider at random per split (default: -1, sqrt(\\# features))\n",
       "\n",
       "\n",
       "\\item \\texttt{n\\_trees}: number of trees to train (default: 10)\n",
       "\n",
       "\n",
       "\\item \\texttt{partial\\_sampling}: fraction of samples to train each tree on (default: 0.7)\n",
       "\n",
       "\n",
       "\\item \\texttt{max\\_depth}: maximum depth of the decision trees (default: no maximum)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_leaf}: the minimum number of samples each leaf needs to have\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_split}: the minimum number of samples in needed for a split\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_purity\\_increase}: minimum purity needed for a split\n",
       "\n",
       "\n",
       "\\item \\texttt{rng}: the random number generator to use. Can be an \\texttt{Int}, which will be used to seed and create a new random number generator.\n",
       "\n",
       "\\end{itemize}\n",
       "Implements \\texttt{fit!}, \\texttt{predict}, \\texttt{predict\\_proba}, \\texttt{get\\_classes}\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "RandomForestClassifier(; n_subfeatures::Int=-1,\n",
       "                       n_trees::Int=10,\n",
       "                       partial_sampling::Float=0.7,\n",
       "                       max_depth::Int=-1,\n",
       "                       rng=Random.GLOBAL_RNG)\n",
       "```\n",
       "\n",
       "Random forest classification. See [DecisionTree.jl's documentation](https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "  * `n_subfeatures`: number of features to consider at random per split (default: -1, sqrt(# features))\n",
       "  * `n_trees`: number of trees to train (default: 10)\n",
       "  * `partial_sampling`: fraction of samples to train each tree on (default: 0.7)\n",
       "  * `max_depth`: maximum depth of the decision trees (default: no maximum)\n",
       "  * `min_samples_leaf`: the minimum number of samples each leaf needs to have\n",
       "  * `min_samples_split`: the minimum number of samples in needed for a split\n",
       "  * `min_purity_increase`: minimum purity needed for a split\n",
       "  * `rng`: the random number generator to use. Can be an `Int`, which will be used to seed and create a new random number generator.\n",
       "\n",
       "Implements `fit!`, `predict`, `predict_proba`, `get_classes`\n"
      ],
      "text/plain": [
       "\u001b[36m  RandomForestClassifier(; n_subfeatures::Int=-1,\u001b[39m\n",
       "\u001b[36m                         n_trees::Int=10,\u001b[39m\n",
       "\u001b[36m                         partial_sampling::Float=0.7,\u001b[39m\n",
       "\u001b[36m                         max_depth::Int=-1,\u001b[39m\n",
       "\u001b[36m                         rng=Random.GLOBAL_RNG)\u001b[39m\n",
       "\n",
       "  Random forest classification. See DecisionTree.jl's documentation\n",
       "  (https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "  Hyperparameters:\n",
       "\n",
       "    •    \u001b[36mn_subfeatures\u001b[39m: number of features to consider at random per split\n",
       "        (default: -1, sqrt(# features))\n",
       "\n",
       "    •    \u001b[36mn_trees\u001b[39m: number of trees to train (default: 10)\n",
       "\n",
       "    •    \u001b[36mpartial_sampling\u001b[39m: fraction of samples to train each tree on\n",
       "        (default: 0.7)\n",
       "\n",
       "    •    \u001b[36mmax_depth\u001b[39m: maximum depth of the decision trees (default: no\n",
       "        maximum)\n",
       "\n",
       "    •    \u001b[36mmin_samples_leaf\u001b[39m: the minimum number of samples each leaf needs to\n",
       "        have\n",
       "\n",
       "    •    \u001b[36mmin_samples_split\u001b[39m: the minimum number of samples in needed for a\n",
       "        split\n",
       "\n",
       "    •    \u001b[36mmin_purity_increase\u001b[39m: minimum purity needed for a split\n",
       "\n",
       "    •    \u001b[36mrng\u001b[39m: the random number generator to use. Can be an \u001b[36mInt\u001b[39m, which will\n",
       "        be used to seed and create a new random number generator.\n",
       "\n",
       "  Implements \u001b[36mfit!\u001b[39m, \u001b[36mpredict\u001b[39m, \u001b[36mpredict_proba\u001b[39m, \u001b[36mget_classes\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
      "Ensemble of Decision Trees"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier\n",
       "n_trees:             50\n",
       "n_subfeatures:       -1\n",
       "partial_sampling:    0.7\n",
       "max_depth:           2\n",
       "min_samples_leaf:    1\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "classes:             ensemble:            "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trees:      50\n",
      "Avg Leaves: 3.22\n",
      "Avg Depth:  2.0"
     ]
    }
   ],
   "source": [
    "DecisionTree.fit!(model, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Iris-virginica\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_iris = [5.9, 3.0, 5.1, 1.9]\n",
    "DecisionTree.predict(model, new_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0 \n",
       " 0.16\n",
       " 0.84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.predict_proba(model, new_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the ordering of the columns in `predict_proba`'s output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"Iris-setosa\"    \n",
       " \"Iris-versicolor\"\n",
       " \"Iris-virginica\" "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.get_classes(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save \"models/random-forest.jld2\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
