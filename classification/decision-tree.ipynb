{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = DecisionTree.load_data(\"iris\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Array{String,1}:\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " ⋮\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = float.(features)\n",
    "labels = string.(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                2\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  nothing\n",
       "root:                     nothing"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTree.DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available models:\n",
    "\n",
    "* `DecisionTreeClassifier`\n",
    "* `DecisionTreeRegressor`\n",
    "* `RandomForestClassifier`\n",
    "* `RandomForestRegressor`\n",
    "* `AdaBoostStumpClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mT\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "DecisionTreeClassifier(; pruning_purity_threshold=0.0,\n",
       "                       max_depth::Int=-1,\n",
       "                       min_samples_leaf::Int=1,\n",
       "                       min_samples_split::Int=2,\n",
       "                       min_purity_increase::Float=0.0,\n",
       "                       n_subfeatures::Int=0,\n",
       "                       rng=Random.GLOBAL_RNG)\n",
       "\\end{verbatim}\n",
       "Decision tree classifier. See \\href{https://github.com/bensadeghi/DecisionTree.jl}{DecisionTree.jl's documentation}\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{pruning\\_purity\\_threshold}: (post-pruning) merge leaves having \\texttt{>=thresh} combined purity (default: no pruning)\n",
       "\n",
       "\n",
       "\\item \\texttt{max\\_depth}: maximum depth of the decision tree (default: no maximum)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_leaf}: the minimum number of samples each leaf needs to have (default: 1)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_split}: the minimum number of samples in needed for a split (default: 2)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_purity\\_increase}: minimum purity needed for a split (default: 0.0)\n",
       "\n",
       "\n",
       "\\item \\texttt{n\\_subfeatures}: number of features to select at random (default: keep all)\n",
       "\n",
       "\n",
       "\\item \\texttt{rng}: the random number generator to use. Can be an \\texttt{Int}, which will be used to seed and create a new random number generator.\n",
       "\n",
       "\\end{itemize}\n",
       "Implements \\texttt{fit!}, \\texttt{predict}, \\texttt{predict\\_proba}, \\texttt{get\\_classes}\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "DecisionTreeClassifier(; pruning_purity_threshold=0.0,\n",
       "                       max_depth::Int=-1,\n",
       "                       min_samples_leaf::Int=1,\n",
       "                       min_samples_split::Int=2,\n",
       "                       min_purity_increase::Float=0.0,\n",
       "                       n_subfeatures::Int=0,\n",
       "                       rng=Random.GLOBAL_RNG)\n",
       "```\n",
       "\n",
       "Decision tree classifier. See [DecisionTree.jl's documentation](https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "  * `pruning_purity_threshold`: (post-pruning) merge leaves having `>=thresh` combined purity (default: no pruning)\n",
       "  * `max_depth`: maximum depth of the decision tree (default: no maximum)\n",
       "  * `min_samples_leaf`: the minimum number of samples each leaf needs to have (default: 1)\n",
       "  * `min_samples_split`: the minimum number of samples in needed for a split (default: 2)\n",
       "  * `min_purity_increase`: minimum purity needed for a split (default: 0.0)\n",
       "  * `n_subfeatures`: number of features to select at random (default: keep all)\n",
       "  * `rng`: the random number generator to use. Can be an `Int`, which will be used to seed and create a new random number generator.\n",
       "\n",
       "Implements `fit!`, `predict`, `predict_proba`, `get_classes`\n"
      ],
      "text/plain": [
       "\u001b[36m  DecisionTreeClassifier(; pruning_purity_threshold=0.0,\u001b[39m\n",
       "\u001b[36m                         max_depth::Int=-1,\u001b[39m\n",
       "\u001b[36m                         min_samples_leaf::Int=1,\u001b[39m\n",
       "\u001b[36m                         min_samples_split::Int=2,\u001b[39m\n",
       "\u001b[36m                         min_purity_increase::Float=0.0,\u001b[39m\n",
       "\u001b[36m                         n_subfeatures::Int=0,\u001b[39m\n",
       "\u001b[36m                         rng=Random.GLOBAL_RNG)\u001b[39m\n",
       "\n",
       "  Decision tree classifier. See DecisionTree.jl's documentation\n",
       "  (https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "  Hyperparameters:\n",
       "\n",
       "    •    \u001b[36mpruning_purity_threshold\u001b[39m: (post-pruning) merge leaves having\n",
       "        \u001b[36m>=thresh\u001b[39m combined purity (default: no pruning)\n",
       "\n",
       "    •    \u001b[36mmax_depth\u001b[39m: maximum depth of the decision tree (default: no\n",
       "        maximum)\n",
       "\n",
       "    •    \u001b[36mmin_samples_leaf\u001b[39m: the minimum number of samples each leaf needs to\n",
       "        have (default: 1)\n",
       "\n",
       "    •    \u001b[36mmin_samples_split\u001b[39m: the minimum number of samples in needed for a\n",
       "        split (default: 2)\n",
       "\n",
       "    •    \u001b[36mmin_purity_increase\u001b[39m: minimum purity needed for a split (default:\n",
       "        0.0)\n",
       "\n",
       "    •    \u001b[36mn_subfeatures\u001b[39m: number of features to select at random (default:\n",
       "        keep all)\n",
       "\n",
       "    •    \u001b[36mrng\u001b[39m: the random number generator to use. Can be an \u001b[36mInt\u001b[39m, which will\n",
       "        be used to seed and create a new random number generator.\n",
       "\n",
       "  Implements \u001b[36mfit!\u001b[39m, \u001b[36mpredict\u001b[39m, \u001b[36mpredict_proba\u001b[39m, \u001b[36mget_classes\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                2\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
       "root:                     Decision Tree\n",
       "Leaves: 3\n",
       "Depth:  2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.fit!(model, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretty print of the tree, to a depth of 5 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3, Threshold 2.45\n",
      "L-> Iris-setosa : 50/50\n",
      "R-> Feature 4, Threshold 1.75\n",
      "    L-> Iris-versicolor : 49/54\n",
      "    R-> Iris-virginica : 45/46\n"
     ]
    }
   ],
   "source": [
    "DecisionTree.print_tree(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Iris-virginica\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_iris = [5.9, 3.0, 5.1, 1.9]\n",
    "DecisionTree.predict(model, new_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.021739130434782608\n",
       " 0.9782608695652174"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.predict_proba(model, new_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the ordering of the columns in `predict_proba`'s output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"Iris-setosa\"\n",
       " \"Iris-versicolor\"\n",
       " \"Iris-virginica\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.get_classes(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using RDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Year</th><th>Lag1</th><th>Lag2</th><th>Lag3</th><th>Lag4</th><th>Lag5</th><th>Volume</th><th>Today</th><th>Direction</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Categorical…</th></tr></thead><tbody><p>6 rows × 9 columns</p><tr><th>1</th><td>2001.0</td><td>0.381</td><td>-0.192</td><td>-2.624</td><td>-1.055</td><td>5.01</td><td>1.1913</td><td>0.959</td><td>Up</td></tr><tr><th>2</th><td>2001.0</td><td>0.959</td><td>0.381</td><td>-0.192</td><td>-2.624</td><td>-1.055</td><td>1.2965</td><td>1.032</td><td>Up</td></tr><tr><th>3</th><td>2001.0</td><td>1.032</td><td>0.959</td><td>0.381</td><td>-0.192</td><td>-2.624</td><td>1.4112</td><td>-0.623</td><td>Down</td></tr><tr><th>4</th><td>2001.0</td><td>-0.623</td><td>1.032</td><td>0.959</td><td>0.381</td><td>-0.192</td><td>1.276</td><td>0.614</td><td>Up</td></tr><tr><th>5</th><td>2001.0</td><td>0.614</td><td>-0.623</td><td>1.032</td><td>0.959</td><td>0.381</td><td>1.2057</td><td>0.213</td><td>Up</td></tr><tr><th>6</th><td>2001.0</td><td>0.213</td><td>0.614</td><td>-0.623</td><td>1.032</td><td>0.959</td><td>1.3491</td><td>1.392</td><td>Up</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Categorical…\\\\\n",
       "\t\\hline\n",
       "\t1 & 2001.0 & 0.381 & -0.192 & -2.624 & -1.055 & 5.01 & 1.1913 & 0.959 & Up \\\\\n",
       "\t2 & 2001.0 & 0.959 & 0.381 & -0.192 & -2.624 & -1.055 & 1.2965 & 1.032 & Up \\\\\n",
       "\t3 & 2001.0 & 1.032 & 0.959 & 0.381 & -0.192 & -2.624 & 1.4112 & -0.623 & Down \\\\\n",
       "\t4 & 2001.0 & -0.623 & 1.032 & 0.959 & 0.381 & -0.192 & 1.276 & 0.614 & Up \\\\\n",
       "\t5 & 2001.0 & 0.614 & -0.623 & 1.032 & 0.959 & 0.381 & 1.2057 & 0.213 & Up \\\\\n",
       "\t6 & 2001.0 & 0.213 & 0.614 & -0.623 & 1.032 & 0.959 & 1.3491 & 1.392 & Up \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×9 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ Year    │ Lag1    │ Lag2    │ Lag3    │ Lag4    │ Lag5    │ Volume  │\n",
       "│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 2001.0  │ 0.381   │ -0.192  │ -2.624  │ -1.055  │ 5.01    │ 1.1913  │\n",
       "│ 2   │ 2001.0  │ 0.959   │ 0.381   │ -0.192  │ -2.624  │ -1.055  │ 1.2965  │\n",
       "│ 3   │ 2001.0  │ 1.032   │ 0.959   │ 0.381   │ -0.192  │ -2.624  │ 1.4112  │\n",
       "│ 4   │ 2001.0  │ -0.623  │ 1.032   │ 0.959   │ 0.381   │ -0.192  │ 1.276   │\n",
       "│ 5   │ 2001.0  │ 0.614   │ -0.623  │ 1.032   │ 0.959   │ 0.381   │ 1.2057  │\n",
       "│ 6   │ 2001.0  │ 0.213   │ 0.614   │ -0.623  │ 1.032   │ 0.959   │ 1.3491  │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket = dataset(\"ISLR\", \"Smarket\")\n",
    "first(smarket, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Lag1</th><th>Lag2</th><th>Lag3</th><th>Lag4</th><th>Lag5</th><th>Volume</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 6 columns</p><tr><th>1</th><td>0.381</td><td>-0.192</td><td>-2.624</td><td>-1.055</td><td>5.01</td><td>1.1913</td></tr><tr><th>2</th><td>0.959</td><td>0.381</td><td>-0.192</td><td>-2.624</td><td>-1.055</td><td>1.2965</td></tr><tr><th>3</th><td>1.032</td><td>0.959</td><td>0.381</td><td>-0.192</td><td>-2.624</td><td>1.4112</td></tr><tr><th>4</th><td>-0.623</td><td>1.032</td><td>0.959</td><td>0.381</td><td>-0.192</td><td>1.276</td></tr><tr><th>5</th><td>0.614</td><td>-0.623</td><td>1.032</td><td>0.959</td><td>0.381</td><td>1.2057</td></tr><tr><th>6</th><td>0.213</td><td>0.614</td><td>-0.623</td><td>1.032</td><td>0.959</td><td>1.3491</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.381 & -0.192 & -2.624 & -1.055 & 5.01 & 1.1913 \\\\\n",
       "\t2 & 0.959 & 0.381 & -0.192 & -2.624 & -1.055 & 1.2965 \\\\\n",
       "\t3 & 1.032 & 0.959 & 0.381 & -0.192 & -2.624 & 1.4112 \\\\\n",
       "\t4 & -0.623 & 1.032 & 0.959 & 0.381 & -0.192 & 1.276 \\\\\n",
       "\t5 & 0.614 & -0.623 & 1.032 & 0.959 & 0.381 & 1.2057 \\\\\n",
       "\t6 & 0.213 & 0.614 & -0.623 & 1.032 & 0.959 & 1.3491 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×6 DataFrame\n",
       "│ Row │ Lag1    │ Lag2    │ Lag3    │ Lag4    │ Lag5    │ Volume  │\n",
       "│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 0.381   │ -0.192  │ -2.624  │ -1.055  │ 5.01    │ 1.1913  │\n",
       "│ 2   │ 0.959   │ 0.381   │ -0.192  │ -2.624  │ -1.055  │ 1.2965  │\n",
       "│ 3   │ 1.032   │ 0.959   │ 0.381   │ -0.192  │ -2.624  │ 1.4112  │\n",
       "│ 4   │ -0.623  │ 1.032   │ 0.959   │ 0.381   │ -0.192  │ 1.276   │\n",
       "│ 5   │ 0.614   │ -0.623  │ 1.032   │ 0.959   │ 0.381   │ 1.2057  │\n",
       "│ 6   │ 0.213   │ 0.614   │ -0.623  │ 1.032   │ 0.959   │ 1.3491  │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(smarket, ==(:Direction), colname -> true);\n",
    "X = select(X, Not([:Year, :Today]))\n",
    "first(X, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CategoricalArray{String,1,UInt8}:\n",
       " \"Down\"\n",
       " \"Up\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = coerce(y, OrderedFactor)\n",
    "classes(y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([842, 376, 460, 518, 77, 190, 442, 79, 986, 58  …  82, 72, 109, 167, 294, 651, 339, 240, 1130, 70], [658, 1052, 205, 457, 66, 1009, 659, 282, 598, 887  …  911, 177, 565, 508, 121, 53, 536, 833, 575, 1163])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @ 8…68\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = @load DecisionTreeClassifier pkg=DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @ 1…71\u001b[39m\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = machine(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @ 1…71\u001b[39m.\n",
      "└ @ MLJBase /home/yuehhua/.julia/packages/MLJBase/O5b6j/src/machines.jl:187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @ 1…71\u001b[39m\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(match, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
